{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Microsoft Applied Robotics Research Library Open Source Samples for Service Robotics This library is a collection of GitHub repositories containing software applications, data sets, and hardware reference designs to support research and education in the fields of service-robotics. Our team invites you to join us in research and engineering efforts that advance how robots can assist and augment the capabilities of human beings. Current projects focus on the field of Human-Robot-Interaction with the goal of providing service robots the means to effectively communicate with humans. In the future we plan to offer new repositories exploring the fields of robot Navigation and object Manipulation . Human-Robot Interaction (HRI) The field of HRI includes robot speech, expressions, gestures, and information access to provide natural user interface methods for robot applications. Labanotation Suite The Labanotation Suite is a collection of applications comprising a system that can be used to give service robots the ability to move in natural and meaningful ways. It includes software tools, source code, sample data, and hardware simulation software that supports experimentation with the concepts presented in the paper Describing Upper-Body Motions Based on Labanotation for Learning-from-Observation Robots (International Journal of Computer Vision, December 2018) . The system consists of compiled gesture capture applications using the Microsoft Kinect sensor device and a Windows 10 PC. Editing tools constructed in Python provide gesture trimming and movement analysis options to identify key points of movment. Output is graphical Labanotation scores as well as movement data expressed in Labanotation and stored in JSON data format. KinectReader: Human Gesture Capture Tool A compiled Windows application that connects to a Kinect sensor device and provides a user interface for capturing and storing gestures performed by human subjects. It's primary output data is human stick-figure joint positions in a CSV format, but can also capture corresponding RGB video and audio at the same time. KinectCaptureEditor: Human Gesture Trimming Tool A compiled Windows application that loads human joint position CSV files produced by the KinectReader or other tools, as well as optional corresponding video and audio files. It provides a timeline-based method to trim audio and video joint movement sequences into representative human gestures. LabanEditor: Gesture Analysis and Labanotation Generator A Python application that loads a Kinect joint CSV file representing a human gesture, provides algorithmic options for automatically extracting keyframes from the gesture that correspond Labanotation data, and provides a graphical user interface for selection and modification of the extracted keyframes. Additionally, it saves the resulting gesture data in a JSON file format suitable for controlling robots running a gesture interpretation driver, as well as .png graphic file renderings of the charts and diagrams used in the interface. MSRAbotSimulation: Gesture Performance with Simulated Robot This Python and browser-based simulation software uses javascript and html code to implement an animated 3D model of the robot and a user interface for selecting and rendering gestures described in the JSON format. A temporary local HTTP server invoked with python or an existing server can be used to host the software and the simulation is run within a modern web browser. The user can choose from a collection of sample gestures, or select a new gesture captured and created using this project's Gesture Authoring Tools. gestureBot Design Kit With a Windows 10 PC, and optionally a 3D-printer and about $350(USD) in electronic servos and parts, the gestureBot Design Kit repository contains all the information needed to build both a virtual and physical desktop companion robot. It includes browser-based simulation and control software based on the Robotis XL series of servo motors. To construct a physical robot, it provides models for 3D-printable body-parts, a parts-list for electronic components, and step-by-step assembly instructions. No soldering is required, but some manual skill is needed to mate small electronic connectors, as well as manipulate small plastic rivets and miniature metal screws to assemble the body components. Gesture Library: Example Set of Upper-Torso Gestures The Gesture Library is a data-set of upper-torso gesture-concept pairs expressed in Labanotation format and stored as JSON files. The data is directly accessed by the Gesture Engine. The library includes a complete listing of the sample database including a video clip of each gesture performed by the gestureBot. Gesture Service: Example Gesture Service Engine The Gesture Service project is a software module constructed with Python and Google's neural network word2vec that takes a text phrase as input and returns a corresponding gesture. Navigation The field of robot navigation includes systems and methods such as simultaneous-location-and-mapping (SLAM), path planning, and map management. HololensNavigation: Self-calibrating Indoor Navigation This project shows how a Hololens device can be placed on the head of Pepper robot and provide a self-calibrating indoor navigation solution within a single room. Manipulation In industrial applications, robotic object manipulation is common where actions are manually programmed and repeated behind safety barriers. In service-robotics scenarios, dynamic environments and safety considerations make the entire field much more challenging. Our projects explore solutions where HRI and Navigation technologies can be leveraged to allow robots to learn from humans to perform manipulation tasks safely and effectively in residential, workplace, and public environments. While we are working towards an open-source object-manipulation sample for service-robotics next year, our team-mates at Microsoft Bonsai are forging ahead with Autonomous Systems for industrial applications. Take a look at Project Moab .","title":"Home"},{"location":"#microsoft-applied-robotics-research-library","text":"","title":"Microsoft Applied Robotics Research Library"},{"location":"#open-source-samples-for-service-robotics","text":"This library is a collection of GitHub repositories containing software applications, data sets, and hardware reference designs to support research and education in the fields of service-robotics. Our team invites you to join us in research and engineering efforts that advance how robots can assist and augment the capabilities of human beings. Current projects focus on the field of Human-Robot-Interaction with the goal of providing service robots the means to effectively communicate with humans. In the future we plan to offer new repositories exploring the fields of robot Navigation and object Manipulation .","title":"Open Source Samples for Service Robotics"},{"location":"#human-robot-interaction-hri","text":"The field of HRI includes robot speech, expressions, gestures, and information access to provide natural user interface methods for robot applications.","title":"Human-Robot Interaction (HRI)"},{"location":"#labanotation-suite","text":"The Labanotation Suite is a collection of applications comprising a system that can be used to give service robots the ability to move in natural and meaningful ways. It includes software tools, source code, sample data, and hardware simulation software that supports experimentation with the concepts presented in the paper Describing Upper-Body Motions Based on Labanotation for Learning-from-Observation Robots (International Journal of Computer Vision, December 2018) . The system consists of compiled gesture capture applications using the Microsoft Kinect sensor device and a Windows 10 PC. Editing tools constructed in Python provide gesture trimming and movement analysis options to identify key points of movment. Output is graphical Labanotation scores as well as movement data expressed in Labanotation and stored in JSON data format.","title":"Labanotation Suite"},{"location":"#kinectreader-human-gesture-capture-tool","text":"A compiled Windows application that connects to a Kinect sensor device and provides a user interface for capturing and storing gestures performed by human subjects. It's primary output data is human stick-figure joint positions in a CSV format, but can also capture corresponding RGB video and audio at the same time.","title":"KinectReader:  Human Gesture Capture Tool"},{"location":"#kinectcaptureeditor-human-gesture-trimming-tool","text":"A compiled Windows application that loads human joint position CSV files produced by the KinectReader or other tools, as well as optional corresponding video and audio files. It provides a timeline-based method to trim audio and video joint movement sequences into representative human gestures.","title":"KinectCaptureEditor:  Human Gesture Trimming Tool"},{"location":"#labaneditor-gesture-analysis-and-labanotation-generator","text":"A Python application that loads a Kinect joint CSV file representing a human gesture, provides algorithmic options for automatically extracting keyframes from the gesture that correspond Labanotation data, and provides a graphical user interface for selection and modification of the extracted keyframes. Additionally, it saves the resulting gesture data in a JSON file format suitable for controlling robots running a gesture interpretation driver, as well as .png graphic file renderings of the charts and diagrams used in the interface.","title":"LabanEditor:   Gesture Analysis and Labanotation Generator"},{"location":"#msrabotsimulation-gesture-performance-with-simulated-robot","text":"This Python and browser-based simulation software uses javascript and html code to implement an animated 3D model of the robot and a user interface for selecting and rendering gestures described in the JSON format. A temporary local HTTP server invoked with python or an existing server can be used to host the software and the simulation is run within a modern web browser. The user can choose from a collection of sample gestures, or select a new gesture captured and created using this project's Gesture Authoring Tools.","title":"MSRAbotSimulation:   Gesture Performance with Simulated Robot"},{"location":"#gesturebot-design-kit","text":"With a Windows 10 PC, and optionally a 3D-printer and about $350(USD) in electronic servos and parts, the gestureBot Design Kit repository contains all the information needed to build both a virtual and physical desktop companion robot. It includes browser-based simulation and control software based on the Robotis XL series of servo motors. To construct a physical robot, it provides models for 3D-printable body-parts, a parts-list for electronic components, and step-by-step assembly instructions. No soldering is required, but some manual skill is needed to mate small electronic connectors, as well as manipulate small plastic rivets and miniature metal screws to assemble the body components.","title":"gestureBot Design Kit"},{"location":"#gesture-library-example-set-of-upper-torso-gestures","text":"The Gesture Library is a data-set of upper-torso gesture-concept pairs expressed in Labanotation format and stored as JSON files. The data is directly accessed by the Gesture Engine. The library includes a complete listing of the sample database including a video clip of each gesture performed by the gestureBot.","title":"Gesture Library:  Example Set of Upper-Torso Gestures"},{"location":"#gesture-service-example-gesture-service-engine","text":"The Gesture Service project is a software module constructed with Python and Google's neural network word2vec that takes a text phrase as input and returns a corresponding gesture.","title":"Gesture Service:   Example Gesture Service Engine"},{"location":"#navigation","text":"The field of robot navigation includes systems and methods such as simultaneous-location-and-mapping (SLAM), path planning, and map management.","title":"Navigation"},{"location":"#hololensnavigation-self-calibrating-indoor-navigation","text":"This project shows how a Hololens device can be placed on the head of Pepper robot and provide a self-calibrating indoor navigation solution within a single room.","title":"HololensNavigation:  Self-calibrating Indoor Navigation"},{"location":"#manipulation","text":"In industrial applications, robotic object manipulation is common where actions are manually programmed and repeated behind safety barriers. In service-robotics scenarios, dynamic environments and safety considerations make the entire field much more challenging. Our projects explore solutions where HRI and Navigation technologies can be leveraged to allow robots to learn from humans to perform manipulation tasks safely and effectively in residential, workplace, and public environments. While we are working towards an open-source object-manipulation sample for service-robotics next year, our team-mates at Microsoft Bonsai are forging ahead with Autonomous Systems for industrial applications. Take a look at Project Moab .","title":"Manipulation"},{"location":"CODE_OF_CONDUCT/","text":"Microsoft Open Source Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct . Resources: Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns","title":"Microsoft Open Source Code of Conduct"},{"location":"CODE_OF_CONDUCT/#microsoft-open-source-code-of-conduct","text":"This project has adopted the Microsoft Open Source Code of Conduct . Resources: Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns","title":"Microsoft Open Source Code of Conduct"},{"location":"RobotFleet/","text":"Microsoft Applied Robotics Research Library Robot Fleet The following design kits can be used to build robots capable of performing the gestures in the Labanoation Gesture Library. gestureBot This is the robot our kit is designed around. The gestureBot is adapted from the Robotis MINI robot kit and uses their newest and low-cost XL-320 servo specifically designed for small-scale humanoid robots. The kit does not require soldering and all of the structural parts can be built with a low-cost desktop 3D printer. MSRAbot This design is the orignal robot created by student interns working for Microsoft Research Asia. The MSRAbot supported initial investigations in using Labanotation for capturing human gestural movements and translation to robot motor controls. The kit is based on the Futaba RS303MR servo and is built from a combination of metal structural components and 3D printed parts. Pepper (coming soon!) Softbank Robotics' Pepper is a commercial medium-scale semi-humanoid service robot used for a range of information kiosk, entertainment, and customer service applications in public settings. MINI (coming soon!) The Robotis MINI is a commercial miniature-scale full humanoid robot kit designed to support education in robot construction and programming. OP2 (coming next year!) Robotis' OP2 is a commercial small-scale full-humanoid robot designed to support education in robotic programming. This robot provides a platform to consider the challenges of adding lower torso movements to our Gesture Library","title":"RobotFleet"},{"location":"RobotFleet/#robot-fleet","text":"The following design kits can be used to build robots capable of performing the gestures in the Labanoation Gesture Library.","title":"Robot Fleet"},{"location":"RobotFleet/#gesturebot","text":"This is the robot our kit is designed around. The gestureBot is adapted from the Robotis MINI robot kit and uses their newest and low-cost XL-320 servo specifically designed for small-scale humanoid robots. The kit does not require soldering and all of the structural parts can be built with a low-cost desktop 3D printer.","title":"gestureBot"},{"location":"RobotFleet/#msrabot","text":"This design is the orignal robot created by student interns working for Microsoft Research Asia. The MSRAbot supported initial investigations in using Labanotation for capturing human gestural movements and translation to robot motor controls. The kit is based on the Futaba RS303MR servo and is built from a combination of metal structural components and 3D printed parts.","title":"MSRAbot"},{"location":"RobotFleet/#pepper-coming-soon","text":"Softbank Robotics' Pepper is a commercial medium-scale semi-humanoid service robot used for a range of information kiosk, entertainment, and customer service applications in public settings.","title":"Pepper (coming soon!)"},{"location":"RobotFleet/#mini-coming-soon","text":"The Robotis MINI is a commercial miniature-scale full humanoid robot kit designed to support education in robot construction and programming.","title":"MINI (coming soon!)"},{"location":"RobotFleet/#op2-coming-next-year","text":"Robotis' OP2 is a commercial small-scale full-humanoid robot designed to support education in robotic programming. This robot provides a platform to consider the challenges of adding lower torso movements to our Gesture Library","title":"OP2 (coming next year!)"},{"location":"SECURITY/","text":"Security Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft , Azure , DotNet , AspNet , Xamarin , and our GitHub organizations . If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability , please report it to us as described below. Reporting Security Issues Please do not report security vulnerabilities through public GitHub issues. Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report . If you prefer to submit without logging in, send email to secure@microsoft.com . If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc . Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs. Preferred Languages We prefer all communications to be in English. Policy Microsoft follows the principle of Coordinated Vulnerability Disclosure .","title":"SECURITY"},{"location":"SECURITY/#security","text":"Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft , Azure , DotNet , AspNet , Xamarin , and our GitHub organizations . If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability , please report it to us as described below.","title":"Security"},{"location":"SECURITY/#reporting-security-issues","text":"Please do not report security vulnerabilities through public GitHub issues. Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report . If you prefer to submit without logging in, send email to secure@microsoft.com . If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc . Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs.","title":"Reporting Security Issues"},{"location":"SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"SECURITY/#policy","text":"Microsoft follows the principle of Coordinated Vulnerability Disclosure .","title":"Policy"},{"location":"SUPPORT/","text":"TODO: The maintainer of this repo has not yet edited this file REPO OWNER : Do you want Customer Service Support (CSS) support for this product/project? No CSS support: Fill out this template with information about how to file issues and get help. Yes CSS support: Fill out an intake form at aka.ms/spot . CSS will work with/help you to determine next steps. More details also available at aka.ms/onboardsupport . Not sure? Fill out a SPOT intake as though the answer were \"Yes\". CSS will help you decide. Then remove this first heading from this SUPPORT.MD file before publishing your repo. Support How to file issues and get help This project uses GitHub Issues to track bugs and feature requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new Issue. For help and questions about using this project, please REPO MAINTAINER: INSERT INSTRUCTIONS HERE FOR HOW TO ENGAGE REPO OWNERS OR COMMUNITY FOR HELP. COULD BE A STACK OVERFLOW TAG OR OTHER CHANNEL. WHERE WILL YOU HELP PEOPLE? . Microsoft Support Policy Support for this PROJECT or PRODUCT is limited to the resources listed above.","title":"TODO: The maintainer of this repo has not yet edited this file"},{"location":"SUPPORT/#todo-the-maintainer-of-this-repo-has-not-yet-edited-this-file","text":"REPO OWNER : Do you want Customer Service Support (CSS) support for this product/project? No CSS support: Fill out this template with information about how to file issues and get help. Yes CSS support: Fill out an intake form at aka.ms/spot . CSS will work with/help you to determine next steps. More details also available at aka.ms/onboardsupport . Not sure? Fill out a SPOT intake as though the answer were \"Yes\". CSS will help you decide. Then remove this first heading from this SUPPORT.MD file before publishing your repo.","title":"TODO: The maintainer of this repo has not yet edited this file"},{"location":"SUPPORT/#support","text":"","title":"Support"},{"location":"SUPPORT/#how-to-file-issues-and-get-help","text":"This project uses GitHub Issues to track bugs and feature requests. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug or feature request as a new Issue. For help and questions about using this project, please REPO MAINTAINER: INSERT INSTRUCTIONS HERE FOR HOW TO ENGAGE REPO OWNERS OR COMMUNITY FOR HELP. COULD BE A STACK OVERFLOW TAG OR OTHER CHANNEL. WHERE WILL YOU HELP PEOPLE? .","title":"How to file issues and get help"},{"location":"SUPPORT/#microsoft-support-policy","text":"Support for this PROJECT or PRODUCT is limited to the resources listed above.","title":"Microsoft Support Policy"}]}